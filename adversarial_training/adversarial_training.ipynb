{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb65205c-eb0c-4a35-a58b-99ed2cdf9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial: https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
    "# FGSM: perturbed_image=image+epsilon∗sign(data_grad)=x+ϵ∗sign(∇ J(θ,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff8850b-9e6b-4f69-b709-02dd41ea8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import wandb\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.data.all import (\n",
    "    CategoryBlock,\n",
    "    DataBlock,\n",
    "    DataLoaders,\n",
    "    RandomSplitter,\n",
    "    RegressionBlock,\n",
    ")\n",
    "\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.vision.data import ImageBlock, ImageDataLoaders\n",
    "from fastai.vision.utils import get_image_files\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from fastai.vision.models import resnet18\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from math import radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce52a45-a888-4f52-bf73-1bac4b7afe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import attacks\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "#from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "from carlini_wagner_l2 import carlini_wagner_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb2d268-8583-468d-8fa8-1f7edd88739e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.11'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1638a92a-a54d-4ee7-a2a6-29847aac2017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: 2\n"
     ]
    }
   ],
   "source": [
    "# Assign GPU\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "print(\"Running on GPU: \" + str(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96088441-1222-4a55-81b4-711bce2a9978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristymnm\u001b[0m (\u001b[33marcslaboratory\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dbea0b8eda48faa801a96a086a1502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016667598198788863, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: /sys/module/amdgpu/initstate: No such file or directory\n",
      "ERROR:root:Driver not initialized (amdgpu not found in modules)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cemb2020/DataAugmentation/adversarial_training/wandb/run-20231026_152355-z0gwss29</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arcslaboratory/DataAugmentation/runs/z0gwss29' target=\"_blank\">eternal-meadow-59</a></strong> to <a href='https://wandb.ai/arcslaboratory/DataAugmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arcslaboratory/DataAugmentation' target=\"_blank\">https://wandb.ai/arcslaboratory/DataAugmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arcslaboratory/DataAugmentation/runs/z0gwss29' target=\"_blank\">https://wandb.ai/arcslaboratory/DataAugmentation/runs/z0gwss29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "run = wandb.init(\n",
    "        project=\"DataAugmentation\",\n",
    "        entity=\"arcslaboratory\",\n",
    "        notes=\"Adversarial Training\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719c1766-c2b8-4241-9642-0d260f213c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_from_filename(rotation_threshold, filename) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the direction label from the filename of an image.\n",
    "\n",
    "    Example: \"path/to/file/001_000011_-1p50.png\" --> \"right\"\n",
    "    \"\"\"\n",
    "    filename_stem = Path(filename).stem\n",
    "    angle = float(filename_stem.split(\"_\")[2].replace(\"p\", \".\"))\n",
    "\n",
    "    if angle > rotation_threshold:\n",
    "        return \"left\"\n",
    "    elif angle < -rotation_threshold:\n",
    "        return \"right\"\n",
    "    else:\n",
    "        return \"forward\"\n",
    "        \n",
    "def get_dls(data_path: str):\n",
    "    # NOTE: not allowed to add a type annotation to the input\n",
    "\n",
    "    image_filenames: list = get_image_files(data_path)  # type:ignore\n",
    "\n",
    "    # Using a partial function to set the rotation_threshold from args\n",
    "    label_func = partial(y_from_filename, radians(5)) # radians(5) = 0.0872665\n",
    "\n",
    "    return ImageDataLoaders.from_name_func(\n",
    "            data_path,\n",
    "            image_filenames,\n",
    "            label_func,\n",
    "            valid_pct=0.2,\n",
    "            bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c05ea0-1b42-4664-8dc6-91c299bbd460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data_folder = \"/home/cemb2020/scr2023/data/WanderingStaticTextures/\"\n",
    "# get model\n",
    "models_folder = \"/data/clark/scr2023/data/WanderingStaticTextures/models/\"\n",
    "model_name = \"wandering-static_rep00.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b0d99e-be62-4df4-9680-6286bcd34fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = load_learner(models_folder + model_name, cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "266f6aee-95ea-498c-819d-ab584b55b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f89a89f-c4f5-4fc0-9696-8445f088d47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, epsilon):\n",
    "\n",
    "    # save right filename f\"000_{i:0>{6}}_-1p00.png\"\n",
    "    # save left filename f\"000_{i:0>{6}}_1p00.png\"\n",
    "    # save forward filename f\"000_{i:0>{6}}_0p00.png\"\n",
    "    \n",
    "    # Accuracy counter\n",
    "    fgsm_correct = 0\n",
    "    pgd_correct = 0\n",
    "    cw_correct = 0\n",
    "    \n",
    "    fgsm_adv_examples = []\n",
    "    pgd_adv_examples = []\n",
    "    cw_adv_examples = []\n",
    "\n",
    "    clean_examples = []\n",
    "    \n",
    "    # Loop over all examples in test set\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        # Forward pass the data through the model\n",
    "        output = learner.model(data)\n",
    "            \n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        \n",
    "        # If the initial prediction is wrong, don't bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Get adversarial examples\n",
    "        #fgsm_ex = fast_gradient_method(learner.model, data, epsilon, np.inf, clip_min=-1, clip_max=1)\n",
    "        #pgd_ex = projected_gradient_descent(learner.model, data, epsilon, 0.005, 40, np.inf, clip_min=-1, clip_max=1, sanity_checks=False)\n",
    "        cw_ex = carlini_wagner_l2(learner.model, data, n_classes=3, clip_min=-1)\n",
    "        \n",
    "        # Re-classify the perturbed image\n",
    "        fgsm_out = learner.model(fgsm_ex)\n",
    "        pgd_out = learner.model(pgd_ex)\n",
    "        cw_out = learner.model(cw_ex)\n",
    "        \n",
    "        # Check for success\n",
    "        fgsm_final_pred = fgsm_out.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        pgd_final_pred = pgd_out.max(1, keepdim=True)[1]\n",
    "        cw_final_pred = cw_out.max(1, keepdim=True)[1]\n",
    "\n",
    "        # collect clean examples\n",
    "        if len(clean_examples) < 5:\n",
    "                ex = data.squeeze().detach().cpu().numpy()\n",
    "                clean_examples.append((init_pred.item(), target.item(), ex))\n",
    "\n",
    "        # keep count of adv examples and save 5 of each\n",
    "        if fgsm_final_pred.item() == target.item():\n",
    "            fgsm_correct += 1\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(fgsm_adv_examples) < 5:\n",
    "                adv_ex = fgsm_ex.squeeze().detach().cpu().numpy()\n",
    "                fgsm_adv_examples.append((init_pred.item(), fgsm_final_pred.item(), adv_ex))    \n",
    "        if pgd_final_pred.item() == target.item():\n",
    "            pgd_correct += 1\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(pgd_adv_examples) < 5:\n",
    "                adv_ex = pgd_ex.squeeze().detach().cpu().numpy()\n",
    "                pgd_adv_examples.append( (init_pred.item(), pgd_final_pred.item(), adv_ex) )\n",
    "        if cw_final_pred.item() == target.item():\n",
    "            cw_correct += 1\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(cw_adv_examples) < 5:\n",
    "                adv_ex = cw_ex.squeeze().detach().cpu().numpy()\n",
    "                cw_adv_examples.append( (init_pred.item(), cw_final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    fgsm_acc = fgsm_correct/float(len(test_loader))\n",
    "    pgd_acc = pgd_correct/float(len(test_loader))\n",
    "    cw_acc = cw_correct/float(len(test_loader))\n",
    "    \n",
    "    print(f\"Epsilon: {epsilon}\\tFGSM Accuracy = {fgsm_correct} / {len(test_loader)} = {fgsm_acc}\")\n",
    "    print(f\"Epsilon: {epsilon}\\tPGD Accuracy = {pgd_correct} / {len(test_loader)} = {pgd_acc}\")\n",
    "    print(f\"CW Accuracy = {cw_correct} / {len(test_loader)} = {cw_acc}\")\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return clean_examples, fgsm_adv_examples, pgd_adv_examples, cw_adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc3ec80-5443-49a3-bca0-382c21d126c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261\n",
      "TensorImage(0.0321, device='cuda:2', grad_fn=<AliasBackward0>)\n",
      "TensorImage(12.1863, device='cuda:2', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run test for each epsilon\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m epsilons:\n\u001b[0;32m---> 10\u001b[0m     clean_ex, fgsm_ex, pgd_ex, cw_ex \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     clean_examples\u001b[38;5;241m.\u001b[39mappend(clean_ex)\n\u001b[1;32m     12\u001b[0m     fgsm_examples\u001b[38;5;241m.\u001b[39mappend(fgsm_ex)\n",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_loader, epsilon)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get adversarial examples\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#fgsm_ex = fast_gradient_method(learner.model, data, epsilon, np.inf, clip_min=-1, clip_max=1)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#pgd_ex = projected_gradient_descent(learner.model, data, epsilon, 0.005, 40, np.inf, clip_min=-1, clip_max=1, sanity_checks=False)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m cw_ex \u001b[38;5;241m=\u001b[39m \u001b[43mcarlini_wagner_l2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Re-classify the perturbed image\u001b[39;00m\n\u001b[1;32m     39\u001b[0m fgsm_out \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mmodel(fgsm_ex)\n",
      "File \u001b[0;32m~/DataAugmentation/adversarial_training/carlini_wagner_l2.py:155\u001b[0m, in \u001b[0;36mcarlini_wagner_l2\u001b[0;34m(model_fn, x, n_classes, y, targeted, lr, confidence, clip_min, clip_max, initial_const, binary_search_steps, max_iterations)\u001b[0m\n\u001b[1;32m    153\u001b[0m loss \u001b[38;5;241m=\u001b[39m (const \u001b[38;5;241m*\u001b[39m f \u001b[38;5;241m+\u001b[39m l2)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[0;32m--> 155\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Update best results\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mambaforge/envs/r_scr2023/lib/python3.10/site-packages/torch/_tensor.py:479\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/opt/mambaforge/envs/r_scr2023/lib/python3.10/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1530\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/mambaforge/envs/r_scr2023/lib/python3.10/site-packages/fastai/torch_core.py:372\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 372\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/mambaforge/envs/r_scr2023/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/mambaforge/envs/r_scr2023/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mambaforge/envs/r_scr2023/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "clean_examples, fgsm_examples, pgd_examples, cw_examples = [], [], [], []\n",
    "\n",
    "image_filenames: list = get_image_files(data_folder)\n",
    "test_loader = learner.dls.test_dl(image_filenames, bs=1, with_labels=True)\n",
    "print(len(test_loader))\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    clean_ex, fgsm_ex, pgd_ex, cw_ex = test(learner, test_loader, eps)\n",
    "    clean_examples.append(clean_ex)\n",
    "    fgsm_examples.append(fgsm_ex)\n",
    "    pgd_examples.append(pgd_ex)\n",
    "    cw_examples.append(cw_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a2d3-047c-4190-bfdd-8a95cda289c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several examples of adversarial samples at each epsilon\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for examples in [clean_examples, fgsm_examples, pgd_examples, cw_examples]:\n",
    "        for j in range(len(examples[i])):\n",
    "            cnt += 1\n",
    "            plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "            plt.xticks([], [])\n",
    "            plt.yticks([], [])\n",
    "            if j == 0:\n",
    "                plt.ylabel(f\"Eps: {epsilons[i]}\", fontsize=14)\n",
    "            orig,adv,ex = examples[i][j]\n",
    "            plt.title(f\"{orig} -> {adv}\")\n",
    "            outmap_min = np.min(ex)\n",
    "            outmap_max = np.max(ex)\n",
    "            ex = (ex - outmap_min) / (outmap_max - outmap_min)\n",
    "            plt.imshow((np.transpose(ex, (1, 2, 0))))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66266727-89d2-48fb-b8d6-71847f7b1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"DataAugmentation\",\n",
    "    entity=\"arcslaboratory\",\n",
    "    notes=\"adversarial example generation\",\n",
    ")\n",
    "\n",
    "if run is None:\n",
    "    raise Exception(\"wandb.init() failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
